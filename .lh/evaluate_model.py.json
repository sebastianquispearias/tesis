{
    "sourceFile": "evaluate_model.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1750636878167,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1750636972644,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,7 @@\n import os\r\n+os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\r\n+\r\n import sys\r\n import argparse\r\n import torch\r\n from torch.utils.data import Dataset, DataLoader\r\n"
                },
                {
                    "date": 1750637038106,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -9,9 +9,9 @@\n import albumentations as A\r\n from albumentations.pytorch import ToTensorV2\r\n import segmentation_models_pytorch as smp\r\n import numpy as np\r\n-\r\n+from tqdm import tqdm\r\n # ----------------------------------------------------\r\n # 0) CONFIGURACIÓN GLOBAL\r\n # ----------------------------------------------------\r\n # Estos parámetros deben ser los mismos que se usaron durante el entrenamiento\r\n"
                }
            ],
            "date": 1750636878167,
            "name": "Commit-0",
            "content": "import os\r\nimport sys\r\nimport argparse\r\nimport torch\r\nfrom torch.utils.data import Dataset, DataLoader\r\nimport cv2\r\nimport albumentations as A\r\nfrom albumentations.pytorch import ToTensorV2\r\nimport segmentation_models_pytorch as smp\r\nimport numpy as np\r\n\r\n# ----------------------------------------------------\r\n# 0) CONFIGURACIÓN GLOBAL\r\n# ----------------------------------------------------\r\n# Estos parámetros deben ser los mismos que se usaron durante el entrenamiento\r\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\nBACKBONE = 'efficientnet-b3'\r\nINPUT_SHAPE = (384, 384)\r\nBATCH_SIZE = 2 # Puede ser más grande para evaluación si tu VRAM lo permite\r\nN_CLASSES = 1\r\n\r\n# ----------------------------------------------------\r\n# A) DATASET Y TRANSFORMACIONES (Copiado de tu script de entrenamiento)\r\n# ----------------------------------------------------\r\nclass CorrosionDataset(Dataset):\r\n    def __init__(self, images_dir, masks_dir, transform=None):\r\n        self.images_fps = sorted([os.path.join(images_dir, fname) for fname in os.listdir(images_dir)])\r\n        self.masks_fps = sorted([os.path.join(masks_dir, fname) for fname in os.listdir(masks_dir)])\r\n        self.transform = transform\r\n\r\n    def __len__(self):\r\n        return len(self.images_fps)\r\n\r\n    def __getitem__(self, idx):\r\n        img = cv2.cvtColor(cv2.imread(self.images_fps[idx]), cv2.COLOR_BGR2RGB)\r\n        mask = cv2.imread(self.masks_fps[idx], cv2.IMREAD_GRAYSCALE)\r\n        mask = (mask > 0).astype('float32')\r\n\r\n        if self.transform:\r\n            augmented = self.transform(image=img, mask=mask)\r\n            img, mask = augmented['image'], augmented['mask']\r\n        \r\n        return img, mask.unsqueeze(0)\r\n\r\n# Solo necesitamos la transformación de validación/test\r\nval_transform = A.Compose([\r\n    A.Resize(*INPUT_SHAPE),\r\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\r\n    ToTensorV2(),\r\n])\r\n\r\n# ----------------------------------------------------\r\n# B) PARSEO DE ARGUMENTOS\r\n# ----------------------------------------------------\r\ndef parse_args():\r\n    p = argparse.ArgumentParser(description=\"Script de Evaluación de Modelos de Segmentación\")\r\n    p.add_argument(\"--weights\", required=True, help=\"Ruta al archivo de pesos del modelo (.pth)\")\r\n    p.add_argument(\"--regime\", required=True, help=\"Régimen de datos a usar para el test (ej: B25, C50)\")\r\n    p.add_argument(\"--data_root\", default=\"data/all_results/regimes\", help=\"Ruta base a los directorios de regímenes\")\r\n    return p.parse_args()\r\n\r\n# ----------------------------------------------------\r\n# C) FUNCIÓN PRINCIPAL DE EVALUACIÓN\r\n# ----------------------------------------------------\r\ndef main():\r\n    args = parse_args()\r\n    print(f\"--- Iniciando Evaluación del Modelo ---\")\r\n    print(f\"  - Pesos: {args.weights}\")\r\n    print(f\"  - Conjunto de Test del Régimen: {args.regime}\")\r\n    print(f\"  - Usando dispositivo: {DEVICE}\")\r\n\r\n    # 1. Construir el Modelo (debe ser idéntico al que se entrenó)\r\n    model = smp.DeepLabV3Plus(\r\n        encoder_name=BACKBONE,\r\n        encoder_weights=None,  # No necesitamos cargar pesos de ImageNet, cargaremos los nuestros\r\n        in_channels=3,\r\n        classes=N_CLASSES\r\n    ).to(DEVICE)\r\n\r\n    # 2. Cargar los pesos entrenados\r\n    model.load_state_dict(torch.load(args.weights, map_location=DEVICE))\r\n    print(\"--> Pesos cargados exitosamente.\")\r\n    \r\n    # 3. Preparar el DataLoader de Test\r\n    test_dir = os.path.join(args.data_root, args.regime, \"test\")\r\n    test_ds = CorrosionDataset(os.path.join(test_dir, \"images\"), os.path.join(test_dir, \"masks\"), transform=val_transform)\r\n    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\r\n\r\n    # 4. Definir Loss y Métricas\r\n    loss_fn = smp.losses.DiceLoss(mode='binary')\r\n    \r\n    # 5. Bucle de Evaluación\r\n    model.eval() # Poner el modelo en modo de evaluación\r\n    test_iou, test_f1, test_loss = 0.0, 0.0, 0.0\r\n    with torch.no_grad(): # No necesitamos calcular gradientes\r\n        loop = tqdm(test_loader, total=len(test_loader), desc=\"Evaluando en Test\")\r\n        for x_test, y_test in loop:\r\n            x_test, y_test = x_test.to(DEVICE), y_test.to(DEVICE)\r\n            \r\n            pred_test = model(x_test)\r\n            test_loss += loss_fn(pred_test, y_test).item()\r\n            \r\n            probs = torch.sigmoid(pred_test)\r\n            y_test_int = y_test.long()\r\n            \r\n            tp, fp, fn, tn = smp.metrics.get_stats(probs, y_test_int, mode='binary', threshold=0.5)\r\n            test_iou += smp.metrics.iou_score(tp, fp, fn, tn, reduction='macro').item()\r\n            test_f1 += smp.metrics.f1_score(tp, fp, fn, tn, reduction='macro').item()\r\n    \r\n    # 6. Calcular y mostrar los resultados finales\r\n    num_batches = len(test_loader)\r\n    final_loss = test_loss / num_batches\r\n    final_iou = test_iou / num_batches\r\n    final_f1 = test_f1 / num_batches\r\n    \r\n    print(\"\\n--- ¡Evaluación Completada! ---\")\r\n    print(f\">> RESULTADO FINAL EN TEST (Régimen: {args.regime}):\")\r\n    print(f\"   - Loss: {final_loss:.4f}\")\r\n    print(f\"   - IoU:  {final_iou:.4f}\")\r\n    print(f\"   - F1:   {final_f1:.4f}\")\r\n\r\nif __name__ == '__main__':\r\n    main()"
        }
    ]
}